# task settings
num_train_frames: 1000000
env_name: tabletop_manipulation_no_walls
policy_switch_frequency: 300
frame_stack: 1
action_repeat: 1
discount: 0.99
# safety critic
use_safety_critic: false
epsilon: 0.1
# stuck function
use_stuck_oracle_for_Q: false
use_stuck_buffer_for_Q: false
use_stuck_discrim_for_Q: false
r_min: 0
method_name: autonomous
# train settings
num_seed_frames: 10000
reward_type: sparse
# eval
eval_every_frames: 10000
num_eval_episodes: 10
# snapshot
save_snapshot: false
# misc
seed: 0
device: cpu
save_video: false
train_video_save_freq: 10
save_train_video: false
use_tb: true
train_horizon: ${num_train_frames}
eval_horizon: 1000
# agent
lr: 3e-4
feature_dim: 50
# stuck parameters
default_stuck_value: 0.0
use_stuck_ratio: false
use_stuck_discrim_label: false
# early termination
switch_policy_threshold: 0
switch_policy_at_condition: false
early_abort_threshold: 0.5
use_Q_value_for_term: false
use_initial_value_for_term: false
use_stuck_discrim_for_term: false
use_oracle_for_term: false
num_action_samples: 10
num_explore_steps: 0
num_stuck_state_samples: 0
replace_goal: true
num_demos: 10

forward_agent:
  _target_: agents.SACAgent
  obs_shape: ??? # to be specified later
  action_shape: ??? # to be specified later
  device: ${device}
  lr: ${lr}
  critic_target_tau: 0.005
  reward_scale_factor: 10.0
  use_tb: ${use_tb}
  hidden_dim: 256
  feature_dim: ${feature_dim}
  from_vision: false
  discount: 0.99
  # stuck discriminator parameters
  stuck_discrim_hidden_size: 128
  stuck_discrim_unsupervised: false
  # replay buffer
  replay_buffer_size: ${num_train_frames}
  nstep: 1
  batch_size: 256
  balanced_buffer: true
  initial_fraction: 0.5
  final_fraction: 0.05
  final_timestep: 100000
  with_replacement: true

backward_agent:
  _target_: agents.MEDALBackwardAgent
  obs_shape: ??? # to be specified later
  action_shape: ??? # to be specified later
  device: ${device}
  lr: ${lr}
  critic_target_tau: 0.005
  reward_scale_factor: 10.0
  use_tb: ${use_tb}
  hidden_dim: 256
  feature_dim: ${feature_dim}
  from_vision: false
  discount: 0.99
  # hidden size of the discriminator
  discrim_hidden_size: 128
  # stuck discriminator parameters
  stuck_discrim_unsupervised: ${forward_agent.stuck_discrim_unsupervised}
  # replay buffer
  replay_buffer_size: ${num_train_frames}
  nstep: 1
  batch_size: 256
  balanced_buffer: false
  initial_fraction: 0.5
  final_fraction: 0.05
  final_timestep: 100000
  with_replacement: true

discriminator:
  train_interval: 10
  train_steps_per_iteration: 1
  # replay buffer
  batch_size: 800
  positive_buffer_size: 100000
  negative_buffer_size: ${num_train_frames}
  with_replacement: true

stuck_discriminator:
  unsupervised: ${forward_agent.stuck_discrim_unsupervised}
  unsupervised_window: 1
  train_interval: 10
  train_steps_per_iteration: 1
  # replay buffer
  batch_size: 800
  positive_buffer_size: ${num_train_frames}
  negative_buffer_size: ${num_train_frames}
  with_replacement: true

hydra:
  run:
    dir: ./exp_local/medal/${env_name}/${method_name}/${seed}/
